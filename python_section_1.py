# -*- coding: utf-8 -*-
"""python_section_1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JWlJAwq9LIX1wSZlQMPUO1UBZD_3dX-B
"""

#Q1)

from typing import List, Dict

def group_by_length(lst: List[str]) -> Dict[int, List[str]]:
    """
    Groups the strings by their length and returns a dictionary.
    """
    result = {}


    for s in lst:
        length = len(s)


        if length not in result:
            result[length] = []
        result[length].append(s)


    return dict(sorted(result.items()))


print(group_by_length(["apple", "bat", "car", "elephant", "dog", "bear"]))

print(group_by_length(["one", "two", "three", "four"]))

#Q2)

from typing import List

def reverse_by_n_elements(lst: List[int], n: int) -> List[int]:
    def reverse_chunk(start, end):
        # Reverse elements from start to end-1 in place
        while start < end:
            lst[start], lst[end] = lst[end], lst[start]
            start += 1
            end -= 1

    result = []
    i = 0
    # Iterate through the list in steps of size n
    while i < len(lst):
        # Find the start and end for the current chunk
        start = i
        end = min(i + n - 1, len(lst) - 1)
        # Reverse the chunk
        while start < end:
            lst[start], lst[end] = lst[end], lst[start]
            start += 1
            end -= 1
        # Move the index by n
        i += n

    return lst

# Example usage
print(reverse_by_n_elements([1, 2, 3, 4, 5, 6, 7, 8], 3))
print(reverse_by_n_elements([1, 2, 3, 4, 5], 2))
print(reverse_by_n_elements([10, 20, 30, 40, 50, 60, 70], 4))

#Q3)

from typing import Dict, Any

def flatten_dict(nested_dict: Dict[str, Any], sep: str = '.') -> Dict[str, Any]:
    """
    Flattens a nested dictionary into a single-level dictionary with dot notation for keys.

    :param nested_dict: The dictionary object to flatten
    :param sep: The separator to use between parent and child keys (defaults to '.')
    :return: A flattened dictionary
    """
    def flatten(sub_dict: Dict[str, Any], parent_key: str = '') -> Dict[str, Any]:
        items = {}

        for key, value in sub_dict.items():
            # Create a new key with the parent key prepended
            new_key = f"{parent_key}{sep}{key}" if parent_key else key

            if isinstance(value, dict):
                # Recursively flatten the sub-dictionary
                items.update(flatten(value, new_key))
            elif isinstance(value, list):
                # Iterate over the list and include the index in the key
                for i, item in enumerate(value):
                    if isinstance(item, dict):
                        items.update(flatten(item, f"{new_key}[{i}]"))
                    else:
                        items[f"{new_key}[{i}]"] = item
            else:
                # Assign the value to the new key
                items[new_key] = value

        return items

    return flatten(nested_dict)

# Example usage
nested_dict = {
    "road": {
        "name": "Highway 1",
        "length": 350,
        "sections": [
            {
                "id": 1,
                "condition": {
                    "pavement": "good",
                    "traffic": "moderate"
                }
            },
            {
                "id": 2,
                "condition": {
                    "pavement": "poor",
                    "traffic": "heavy"
                }
            }
        ]
    }
}

flattened = flatten_dict(nested_dict)
print(flattened)

#Q4)

from typing import List

def unique_permutations(nums: List[int]) -> List[List[int]]:
    """
    Generate all unique permutations of a list that may contain duplicates.

    :param nums: List of integers (may contain duplicates)
    :return: List of unique permutations
    """
    def backtrack(start: int):
        # If we reach the end of the array, we found a unique permutation
        if start == len(nums):
            result.append(nums[:])  # Add a copy of the current permutation
            return

        seen = set()  # To track the numbers we have used in this position
        for i in range(start, len(nums)):
            # If the number has already been used in this position, skip it
            if nums[i] in seen:
                continue
            seen.add(nums[i])  # Mark this number as used
            nums[start], nums[i] = nums[i], nums[start]  # Swap for the current position
            backtrack(start + 1)  # Recurse for the next position
            nums[start], nums[i] = nums[i], nums[start]  # Backtrack (swap back)

    nums.sort()  # Sort the numbers to ensure duplicates are adjacent
    result = []
    backtrack(0)
    return result

# Example usage
input_list = [1, 1, 2]
output = unique_permutations(input_list)
print(output)

#Q5)

import re
from typing import List

def find_all_dates(text: str) -> List[str]:
    """
    This function takes a string as input and returns a list of valid dates
    in 'dd-mm-yyyy', 'mm/dd/yyyy', or 'yyyy.mm.dd' format found in the string.

    Parameters:
    text (str): A string containing the dates in various formats.

    Returns:
    List[str]: A list of valid dates in the formats specified.
    """
    # Define the regex pattern for matching the date formats
    date_pattern = r'\b(?:\d{2}-\d{2}-\d{4}|\d{2}/\d{2}/\d{4}|\d{4}\.\d{2}\.\d{2})\b'

    # Use re.findall to get all matches of the pattern in the text
    valid_dates = re.findall(date_pattern, text)

    return valid_dates

# Example usage
text = "I was born on 23-08-1994, my friend on 08/23/1994, and another one on 1994.08.23."
output = find_all_dates(text)
print(output)  # Output: ['23-08-1994', '08/23/1994', '1994.08.23']

#Q6)

pip install polyline

import polyline
import pandas as pd
import numpy as np

def haversine(lat1, lon1, lat2, lon2):
    """
    Calculate the great-circle distance between two points
    on the Earth specified in decimal degrees (latitude and longitude).
    """
    # Convert latitude and longitude from degrees to radians
    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])

    # Haversine formula
    dlon = lon2 - lon1
    dlat = lat2 - lat1
    a = np.sin(dlat / 2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2)**2
    c = 2 * np.arcsin(np.sqrt(a))

    # Radius of Earth in meters
    r = 6371000
    return c * r

def polyline_to_dataframe(polyline_str: str) -> pd.DataFrame:
    """
    Converts a polyline string into a DataFrame with latitude, longitude,
    and distance between consecutive points.

    Args:
        polyline_str (str): The encoded polyline string.

    Returns:
        pd.DataFrame: A DataFrame containing latitude, longitude, and distance in meters.
    """
    # Decode the polyline string into coordinates
    coordinates = polyline.decode(polyline_str)

    # Create a DataFrame with latitude and longitude
    df = pd.DataFrame(coordinates, columns=['latitude', 'longitude'])

    # Initialize the distance column with 0
    df['distance'] = 0.0

    # Calculate the distance for each coordinate
    for i in range(1, len(df)):
        df.at[i, 'distance'] = haversine(
            df.at[i-1, 'latitude'], df.at[i-1, 'longitude'],
            df.at[i, 'latitude'], df.at[i, 'longitude']
        )

    return df

# Example usage with a valid polyline string
polyline_str = "u{~vF~xhK_VpS_@bDkBvGq@lT_B~D"
df = polyline_to_dataframe(polyline_str)
print(df)

#Q7)

from typing import List

def rotate_and_multiply_matrix(matrix: List[List[int]]) -> List[List[int]]:
    """
    Rotate the given matrix by 90 degrees clockwise, then multiply each element
    by the sum of its original row and column index before rotation.

    Args:
    - matrix (List[List[int]]): 2D list representing the matrix to be transformed.

    Returns:
    - List[List[int]]: A new 2D list representing the transformed matrix.
    """
    if not matrix or not matrix[0]:
        return []

    n = len(matrix)

    # Step 1: Rotate the matrix by 90 degrees clockwise
    rotated = [[0] * n for _ in range(n)]
    for i in range(n):
        for j in range(n):
            rotated[j][n - 1 - i] = matrix[i][j]

    # Step 2: Multiply each element by the sum of its original row and column indices
    transformed = [[0] * n for _ in range(n)]
    for i in range(n):
        for j in range(n):
            original_row_index = i
            original_col_index = j
            # Calculate the sum of the original indices
            index_sum = original_row_index + original_col_index
            # Multiply the rotated element by the sum of indices
            transformed[i][j] = rotated[i][j] * index_sum

    return transformed

# Example usage
input_matrix = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]
result_matrix = rotate_and_multiply_matrix(input_matrix)
print(result_matrix)

#Q8)

import pandas as pd
from datetime import datetime, timedelta
df = pd.read_csv("C:/Users/DPU-ResmMed-S/Downloads/dataset-1.csv")
def time_check(df):
    """
    Verify the completeness of the time data by checking whether the timestamps
    for each unique (id, id_2) pair cover a full 24-hour and 7 days period.

    Parameters:
        df (pd.DataFrame): The DataFrame containing the data.

    Returns:
        pd.Series: A boolean series indicating if each (id, id_2) pair has incorrect timestamps.
    """

    # Define a reference date (for example, the first day of the current week)
    reference_date = datetime.now()  # Use the current date as the reference
    reference_weekday = reference_date.weekday()  # Get the current weekday (0=Monday, 6=Sunday)

    # Mapping of weekdays to their corresponding offset from the reference date
    day_offset = {
        "Monday": 0,
        "Tuesday": 1,
        "Wednesday": 2,
        "Thursday": 3,
        "Friday": 4,
        "Saturday": 5,
        "Sunday": 6,
    }

    # Create datetime columns
    df['start_datetime'] = pd.to_datetime(
        (reference_date - timedelta(days=reference_weekday) + pd.to_timedelta(df['startDay'].map(day_offset), unit='D')).astype(str) + ' ' + df['startTime']
    )

    df['end_datetime'] = pd.to_datetime(
        (reference_date - timedelta(days=reference_weekday) + pd.to_timedelta(df['endDay'].map(day_offset), unit='D')).astype(str) + ' ' + df['endTime']
    )

    # Group by (id, id_2)
    # Additional logic to check for the completeness of the timestamps

    # Example: Check if the datetime range covers a full week
    result = df.groupby(['id', 'id_2']).apply(
        lambda group: (group['start_datetime'].min() <= group['end_datetime'].max())
    )

    return result

# Example usage
# Load your DataFrame from the CSV
# df = pd.read_csv('dataset-1.csv')
incorrect_timestamps = time_check(df)
print(incorrect_timestamps)

